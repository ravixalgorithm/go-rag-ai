# Go RAG AI â€“ Multi-LLM Terminal Chatbot

A terminal-based RAG (Retrieval-Augmented Generation) chatbot built in Go with **multi-provider LLM support**. Switch between providers on the fly without restarting!

## âœ¨ Features

- ğŸ”„ **Multi-LLM Support** â€“ Groq, OpenAI, Anthropic, Gemini, OpenRouter
- ğŸ”€ **Runtime Model Switching** â€“ Use `/model <provider>` to switch mid-chat
- ğŸ’¬ **Conversation Memory** â€“ Maintains context across messages
- ğŸ¨ **Colorful Terminal UI** â€“ Syntax highlighting for code blocks
- âŒ¨ï¸ **Slash Commands** â€“ `/clear`, `/history`, `/exit`, `/model`
- ğŸ›¡ï¸ **Graceful Exit** â€“ Clean shutdown with Ctrl+C

## ğŸš€ Supported Providers

| Provider | Default Model | API Key Env Var |
|----------|---------------|-----------------|
| Groq | llama-3.3-70b-versatile | `GROQ_API_KEY` |
| OpenAI | gpt-4o-mini | `OPENAI_API_KEY` |
| Anthropic | claude-3-5-sonnet-20241022 | `ANTHROPIC_API_KEY` |
| Gemini | gemini-1.5-flash | `GEMINI_API_KEY` |
| OpenRouter | meta-llama/llama-3.1-8b-instruct:free | `OPENROUTER_API_KEY` |

## ğŸ“‹ Prerequisites

- Go 1.21+
- API key from at least one provider

## ğŸ› ï¸ Installation

```bash
# Clone the repository
git clone https://github.com/ravixalgorithm/go-rag-ai.git
cd go-rag-ai

# Install dependencies
go mod download

# Create .env file
cp .env.example .env

# Edit .env and add your API keys
```

## â–¶ï¸ Usage

```bash
go run .
```

Or build and run the executable:

```bash
go build -o go-rag-ai.exe .
./go-rag-ai.exe
```

### Commands

| Command | Description |
|---------|-------------|
| `/model <provider> [model]` | Switch LLM provider (e.g., `/model openai gpt-4o`) |
| `/history` | View conversation history |
| `/clear` | Clear the screen |
| `/exit` | Exit the chatbot |
| `Ctrl+C` | Graceful exit |

### Example

```
You (12:00:00): /model anthropic
âœ… Switched to anthropic / claude-3-5-sonnet-20241022

You (12:00:05): Hello!
anthropic (12:00:07): Hello! How can I assist you today?
```

## ğŸ“ Project Structure

```
go-rag-ai/
â”œâ”€â”€ main.go              # Entry point
â”œâ”€â”€ config.go            # Configuration & env loading
â”œâ”€â”€ chat.go              # Chat loop & commands
â”œâ”€â”€ internal/llm/        # LLM provider clients
â”‚   â”œâ”€â”€ client.go        # LLMClient interface
â”‚   â”œâ”€â”€ factory.go       # Provider factory
â”‚   â”œâ”€â”€ groq_client.go
â”‚   â”œâ”€â”€ openai_client.go
â”‚   â”œâ”€â”€ anthropic_client.go
â”‚   â”œâ”€â”€ gemini_client.go
â”‚   â””â”€â”€ openrouter_client.go
â”œâ”€â”€ .env.example         # Environment template
â””â”€â”€ README.md
```

## ğŸ”§ Configuration

Set environment variables in `.env`:

```bash
# Choose provider: groq, openai, anthropic, gemini, openrouter
LLM_PROVIDER=groq

# Add API keys for providers you want to use
GROQ_API_KEY=your_key
OPENAI_API_KEY=your_key
ANTHROPIC_API_KEY=your_key
GEMINI_API_KEY=your_key
OPENROUTER_API_KEY=your_key

# Optional: override default model
LLM_MODEL=llama-3.3-70b-versatile
```

## ğŸ“„ License

[MIT](./LICENSE)

## ğŸ¤ Contributing

Contributions welcome! Feel free to open issues or submit pull requests.
